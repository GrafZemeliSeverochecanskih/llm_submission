{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237fac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from IPython.display import display\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from sklearn.metrics import f1_score, hamming_loss, jaccard_score\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "lang = \"fr\"\n",
    "base_path = \"XED/processed\"\n",
    "model_name = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "\n",
    "PARAMS = {\n",
    "    \"r\": 8,\n",
    "    \"lora_alpha\": 32,\n",
    "    \"lora_dropout\": 0.10\n",
    "}\n",
    "\n",
    "LORA_TARGET_MODULES = [\n",
    "    \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "    \"up_proj\", \"down_proj\", \"gate_proj\"\n",
    "]\n",
    "\n",
    "\n",
    "def predict_emotions_fr(\n",
    "    model, tokenizer, df, max_samples=300\n",
    ") -> (List[str], List[str]):\n",
    "    preds, golds = [], []\n",
    "    model.eval()\n",
    "    for _, row in tqdm(\n",
    "        df.head(max_samples).iterrows(), total=min(len(df), max_samples)\n",
    "    ):\n",
    "        prompt = f\"Classez l'émotion dans cette phrase : {row['text']}\\nÉmotion :\"\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "        if \"token_type_ids\" in inputs:\n",
    "            inputs.pop(\"token_type_ids\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=10,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "                temperature=0.7,\n",
    "                do_sample=True,\n",
    "            )\n",
    "\n",
    "        pred_text = tokenizer.decode(\n",
    "            output[0][inputs['input_ids'].shape[1]:],\n",
    "            skip_special_tokens=True\n",
    "        ).strip().lower()\n",
    "        preds.append(pred_text)\n",
    "        golds.append(str(row[\"labels\"]))\n",
    "    return preds, golds\n",
    "\n",
    "\n",
    "def compute_metrics_numeric(preds, golds):\n",
    "    all_labels = [str(i) for i in range(1, 9)]\n",
    "    y_true = np.zeros((len(golds), len(all_labels)))\n",
    "    y_pred = np.zeros((len(golds), len(all_labels)))\n",
    "\n",
    "    for i, (g, p) in enumerate(zip(golds, preds)):\n",
    "        true_ids = [s.strip() for s in str(g).split(\",\") if s.strip().isdigit()]\n",
    "        pred_ids = re.findall(r'\\b[1-8]\\b', str(p))\n",
    "\n",
    "        for t in true_ids:\n",
    "            if t in all_labels:\n",
    "                y_true[i, all_labels.index(t)] = 1\n",
    "        for t in pred_ids:\n",
    "            if t in all_labels:\n",
    "                y_pred[i, all_labels.index(t)] = 1\n",
    "\n",
    "    metrics = {\n",
    "        \"micro_f1\": f1_score(\n",
    "            y_true, y_pred, average=\"micro\", zero_division=0\n",
    "        ),\n",
    "        \"macro_f1\": f1_score(\n",
    "            y_true, y_pred, average=\"macro\", zero_division=0\n",
    "        ),\n",
    "        \"jaccard\": jaccard_score(\n",
    "            y_true, y_pred, average=\"samples\", zero_division=0\n",
    "        ),\n",
    "        \"hamming\": hamming_loss(y_true, y_pred),\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def preprocess_function_fr(examples):\n",
    "    texts = [\n",
    "        f\"Classez l'émotion dans cette phrase : {t}\\nÉmotion : {l}\"\n",
    "        for t, l in zip(examples[\"text\"], examples[\"labels\"])\n",
    "    ]\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "\n",
    "print(f\"--- Loading French Data (lang: {lang}) ---\")\n",
    "try:\n",
    "    train_df = pd.read_csv(os.path.join(base_path, f\"train_{lang}.csv\"))\n",
    "    test_df = pd.read_csv(os.path.join(base_path, f\"test_{lang}.csv\"))\n",
    "    print(f\"Train samples: {len(train_df)}\")\n",
    "    print(f\"Test samples: {len(test_df)}\")\n",
    "except FileNotFoundError:\n",
    "    print(\n",
    "        f\"Error: Could not find data files for language '{lang}'. \"\n",
    "        f\"Please ensure 'train_{lang}.csv' and 'test_{lang}.csv' \"\n",
    "        f\"exist in '{base_path}'.\"\n",
    "    )\n",
    "    exit()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side='left')\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"--- Tokenizing Data ---\")\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "tokenized_train = train_dataset.map(\n",
    "    preprocess_function_fr,\n",
    "    batched=True,\n",
    "    remove_columns=train_dataset.column_names\n",
    ")\n",
    "tokenized_test = test_dataset.map(\n",
    "    preprocess_function_fr,\n",
    "    batched=True,\n",
    "    remove_columns=test_dataset.column_names\n",
    ")\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "print(f\"\\n--- Running Zero-Shot Baseline Evaluation on {model_name} ---\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16 if torch.cuda.is_available() else None\n",
    ")\n",
    "base_model.resize_token_embeddings(len(tokenizer))\n",
    "base_model.to(device)\n",
    "base_model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "base_preds, base_golds = predict_emotions_fr(\n",
    "    base_model, tokenizer, test_df, max_samples=300\n",
    ")\n",
    "base_metrics = compute_metrics_numeric(base_preds, base_golds)\n",
    "print(f\"Base Model Metrics ({model_name}):\")\n",
    "print(base_metrics)\n",
    "\n",
    "del base_model\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\n--- Setting up LoRA Fine-Tuning with {model_name} and Best Params ---\")\n",
    "base_model_ft = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16 if torch.cuda.is_available() else None\n",
    ")\n",
    "base_model_ft.resize_token_embeddings(len(tokenizer))\n",
    "base_model_ft.to(device)\n",
    "base_model_ft.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=PARAMS[\"r\"],\n",
    "    lora_alpha=PARAMS[\"lora_alpha\"],\n",
    "    target_modules=LORA_TARGET_MODULES,\n",
    "    lora_dropout=PARAMS[\"lora_dropout\"],\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(base_model_ft, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"./{lang}_gpt_results/final_lora_qwen_{lang}_best\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=5,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=f\"./logs_qwen_{lang}_final\",\n",
    "    report_to=\"none\",\n",
    "    fp16=True if torch.cuda.is_available() and device.type != 'cpu' else False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "print(f\"\\n--- Starting LoRA Fine-Tuning with {model_name} (French) ---\")\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\n--- Running Final Fine-Tuned Model Evaluation ---\")\n",
    "preds, golds = predict_emotions_fr(\n",
    "    model, tokenizer, test_df, max_samples=300\n",
    ")\n",
    "metrics = compute_metrics_numeric(preds, golds)\n",
    "print(f\"Fine-Tuned Model Metrics ({model_name} - Final):\")\n",
    "print(metrics)\n",
    "\n",
    "save_dir = f\"./weights/qwen/lora_qwen_{lang}_best_final\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "model.save_pretrained(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "print(f\"\\nFinal fine-tuned model saved to {save_dir}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
